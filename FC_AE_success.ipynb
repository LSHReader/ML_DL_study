{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#이 코드 파일이 존재하는 working directory에 mlp_img 폴더가 없으면, mlp_img 폴더 생성 \n",
    "f not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input image 변환을 위한 함수\n",
    "def to_img_latent(x):\n",
    "    x = 0.5 * (x + 1)  \n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 2, 2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output image 변환을 위한 함수\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)  \n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST data 받아오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader  \n",
    "from torchvision.datasets import MNIST  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100 #training data 전체(여기서는 6만개)를 딱 한 번 사용했을 때, 한 epoch이 지나갔다고 말함 \n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_transform = transforms.Compose([  #composes several transforms together  \n",
    "    transforms.ToTensor(), #여기서는 PIL.Image.Image 를 tensor로 바꿔줌 \n",
    "    transforms.Normalize((0.5,), (0.5,)) #channel 1이므로 각 1개의 element에 해당하는 mean / stdev \n",
    "])  \n",
    "\n",
    "\n",
    "dataset = MNIST('./data', transform=img_transform, download  = True) #default 옵션은 train = True \n",
    "#Dataloader은 Iterator을 반환한다\n",
    "#배치사이즈만큼 데이터를 로드해줌\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ./data\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.5,), std=(0.5,))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "print(dataset)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        생성자에서 2개의 nn.Sequential 모듈을 생성하고, 멤버변수(self.encoder, self.decoder)로 지정한다.  \n",
    "        \"\"\"\n",
    "        super(autoencoder, self).__init__() # 부모클래스(nn.Module)에서 정의된 메소드를 호출, 생성자 선언 \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True), #inplace = True 옵션 -> 또 다른 객체를 반환하지 않고 기존 객체를 수정, 메모리를 아주 조금 save 할 수 있다.    \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 4))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(4, 12),\n",
    "            nn.ReLU(True),  # ReLU를 쓰는 이유는 이게 generation이 아니라 classification이 목적이라서,, 데이터를 많이 버리는 게 좋음 \n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True), nn.Linear(128, 28 * 28), nn.Tanh()) #마지막 layer에 softmax?\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        순전파 함수에서는 입력 데이터의 Variable을 받아서 출력 데이터의 Variable을\n",
    "        반환해야 합니다. Variable 상의 임의의 연산자뿐만 아니라 생성자에서 정의한\n",
    "        모듈을 사용할 수 있습니다.\n",
    "        \"\"\"\n",
    "        x_latent = self.encoder(x)\n",
    "        x_output = self.decoder(x_latent)\n",
    "        \n",
    "        return x_latent, x_output \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:0.1397\n",
      "torch.Size([96, 4])\n",
      "torch.Size([96, 784])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        inputs, label = data #inputs.shape = [128,1,28,28], label = [128]\n",
    "        inputs = inputs.view(inputs.size(0), -1)  #view는 size변경. inputs.size(0) = 128. 즉 inputs의 size를 [128,784]로 바꿔줌 \n",
    "        inputs = Variable(inputs) # \n",
    "        # ===================forward=====================\n",
    "        latent, output = model(inputs) #autoencoder내에서 forward 진행됨\n",
    "        loss = criterion(output, inputs) \n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.data))\n",
    "    #\n",
    "    if epoch % 10 == 0:\n",
    "        #latent의 이미지 보여주기\n",
    "        print(latent.shape)\n",
    "        pic = to_img_latent(latent.cpu().data)  #to_img를 따로 만들어야 할 것 같은데.. \n",
    "        save_image(pic, './mlp_img/latent_{}.png'.format(epoch))  \n",
    "        \n",
    "        #output의 이미지 보여주기\n",
    "        print(output.shape)\n",
    "        pic = to_img(output.cpu().data)  \n",
    "        save_image(pic, './mlp_img/output_{}.png'.format(epoch))  \n",
    "\n",
    "torch.save(model.state_dict(), './sim_autoencoder.pth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential()\n"
     ]
    }
   ],
   "source": [
    "#print(help(autoencoder))  \n",
    "#print(dir(autoencoder))\n",
    "print(nn.Sequential())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output 가지고 classification 결과 내서, test accuracy 구해야함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
